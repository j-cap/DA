{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook star_model.ipynb to script\n",
      "[NbConvertApp] Writing 16622 bytes to star_model.py\n"
     ]
    }
   ],
   "source": [
    "# convert jupyter notebook to python script\n",
    "!jupyter nbconvert --to script star_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import lstsq\n",
    "from scipy.linalg import block_diag\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from smooth import Smooths as s\n",
    "from smooth import TensorProductSmooths as tps\n",
    "from TensorProductSplines import TensorProductSpline as t\n",
    "from bspline import B_spline as b\n",
    "from penalty_matrix import PenaltyMatrix\n",
    "from DiagnosticPlot import DiagnosticPlotter\n",
    "\n",
    "class StarModel(DiagnosticPlotter):\n",
    "    \n",
    "    possible_penalties = { \"smooth\": PenaltyMatrix().D2_difference_matrix, \n",
    "                           \"inc\": PenaltyMatrix().D1_difference_matrix,\n",
    "                           \"dec\": PenaltyMatrix().D1_difference_matrix,\n",
    "                           \"conc\": PenaltyMatrix().D2_difference_matrix, \n",
    "                           \"conv\": PenaltyMatrix().D2_difference_matrix,\n",
    "                           \"peak\": None }\n",
    "    \n",
    "    def __init__(self, descr):\n",
    "        \"\"\"\n",
    "        descr : tuple - ever entry describens one part of \n",
    "                        the model, e.g.\n",
    "                        descr =( (\"s(1)\", \"smooth\", 10, 1),\n",
    "                                 (\"s(2)\", \"inc\", 10, 1), \n",
    "                                 (\"t(1,2)\", \"tps\", [5,5], 1) \n",
    "                               )\n",
    "                        with the scheme: (type of smooth, number of knots)\n",
    "               \n",
    "        TODO:\n",
    "            [x] incorporate tensor product splines\n",
    "        \"\"\"\n",
    "        self.description_str = descr\n",
    "        self.description_dict = {\n",
    "            t: {\"constraint\": p, \"n_param\": n, \n",
    "                \"lambda\" : {\"smoothness\": l[0], \"constraint\": l[1]}\n",
    "               } \n",
    "            for t, p, n, l  in self.description_str}\n",
    "        self.smooths = None\n",
    "        self.coef_ = None\n",
    "        self.y = None\n",
    "        self.X = None\n",
    "        \n",
    "    def create_basis(self, X, y=None):\n",
    "        \"\"\"Create the unpenalized BSpline basis for the data X.\n",
    "        \n",
    "        Parameters:\n",
    "        ------------\n",
    "        X : np.ndarray - data\n",
    "        y : np.ndarray or None  - For peak/valley penalty. \n",
    "                                  Catches assertion if None and peak or valley penalty. \n",
    "        TODO:\n",
    "            [x] include TPS\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.smooths = list()\n",
    "        self.y = y\n",
    "        \n",
    "        for k,v in self.description_dict.items():\n",
    "            if k[0] is \"s\":\n",
    "                self.smooths.append(\n",
    "                    s(\n",
    "                        x_data=X[:,int(k[2])-1], \n",
    "                        n_param=v[\"n_param\"], \n",
    "                        penalty=v[\"constraint\"], \n",
    "                        y_peak_or_valley=y,\n",
    "                        lam_s=v[\"lambda\"][\"smoothness\"],\n",
    "                        lam_c=v[\"lambda\"][\"constraint\"]\n",
    "                    )\n",
    "                )\n",
    "            elif k[0] is \"t\":\n",
    "                self.smooths.append(\n",
    "                    tps(\n",
    "                        x_data=X[:, [int(k[2])-1, int(k[4])-1]], \n",
    "                        n_param=list(v[\"n_param\"]), \n",
    "                        penalty=v[\"constraint\"],\n",
    "                        lam_s=v[\"lambda\"][\"smoothness\"],\n",
    "                        lam_c=v[\"lambda\"][\"constraint\"]\n",
    "                    )\n",
    "                )    \n",
    "        \n",
    "        self.basis = np.concatenate([smooth.basis for smooth in self.smooths], axis=1) \n",
    "               \n",
    "        self.smoothness_penalty_list = [np.sqrt(s.lam_smooth) * s.Smoothness_matrix() for s in self.smooths]\n",
    "        self.smoothness_penalty_matrix = block_diag(*self.smoothness_penalty_list)\n",
    "\n",
    "        n_coef_list = [0] + [np.product(smooth.n_param) for smooth in self.smooths]\n",
    "        n_coef_cumsum = np.cumsum(n_coef_list)\n",
    "        self.coef_list = n_coef_cumsum\n",
    "        \n",
    "        X_fit = np.copy(X)\n",
    "        X_fit.sort(axis=0)\n",
    "        self.X_fit = X_fit\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def create_basis_for_prediction(self, X=None):\n",
    "        \"\"\"Creates unpenalized BSpline basis for the data X.\n",
    "        \n",
    "        Parameters:\n",
    "        X : np.ndarray - data\n",
    "        \"\"\"\n",
    "        \n",
    "        if X is None:\n",
    "            X = self.X_pred\n",
    "                \n",
    "        self.pred_smooths = list()\n",
    "        for k,v in self.description_dict.items():\n",
    "            if k[0] is \"s\":\n",
    "                self.pred_smooths.append(s(x_data=X[:,int(k[2])-1], n_param=v[\"n_param\"]))\n",
    "            elif k[0] is \"t\":\n",
    "                self.pred_smooths.append(tps(x_data=X[:, [int(k[2])-1, int(k[4])-1]], n_param=list(v[\"n_param\"])))    \n",
    "        \n",
    "        self.basis_for_prediction = np.concatenate([smooth.basis for smooth in self.pred_smooths], axis=1)\n",
    "\n",
    "        X.sort(axis=0)\n",
    "        del self.X_pred\n",
    "        self.X_pred = X\n",
    "        \n",
    "        return\n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "    def create_penalty_block_matrix(self, beta_test=None):\n",
    "        \"\"\"Create the penalty block matrix specified in self.description_str.\n",
    "        \n",
    "        Looks like: ------------\n",
    "                    |p1 0  0  0|  \n",
    "                    |0 p2  0  0|\n",
    "                    |0  0 p3  0|\n",
    "                    |0  0  0 p4|\n",
    "                    ------------\n",
    "        where p_i is a a matrix according to the specified penalty.\n",
    "\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        beta_test  : array  - Test beta for sanity checks.\n",
    "        lam_c      : array  - Array of lambdas for the different constraints. \n",
    "        \n",
    "        TODO:\n",
    "            [x]  include the weights !!! \n",
    "            [x]  include TPS smoothnes penalty\n",
    "            [ ]  include TPS shape penalty\n",
    "        \n",
    "        \"\"\"\n",
    "        assert (self.smooths is not None), \"Run Model.create_basis() first!\"\n",
    "        assert (self.y is not None), \"Run Model.fit(X,y) first!\"\n",
    "        \n",
    "        if beta_test is None:\n",
    "            beta_test = np.zeros(self.basis.shape[1])\n",
    "        \n",
    "        idx = 0      \n",
    "        penalty_matrix_list = []\n",
    "        \n",
    "        for smooth in self.smooths:\n",
    "            \n",
    "            n = smooth.basis.shape[1]\n",
    "            b = beta_test[idx:idx+n]\n",
    "            \n",
    "            D = smooth.penalty_matrix\n",
    "            V = check_constraint(beta=b, constraint=smooth.penalty, y=self.y, basis=smooth.basis)\n",
    "            \n",
    "            penalty_matrix_list.append(smooth.lam_constraint * D.T @ V @ D )\n",
    "            idx += n\n",
    "            \n",
    "        #self.penalty_matrix_list_and_weight = np.concatenate(penalty_matrix_list, axis=1)\n",
    "        self.penalty_matrix_list = penalty_matrix_list\n",
    "        self.penalty_block_matrix = block_diag(*penalty_matrix_list)\n",
    "\n",
    "        return\n",
    "       \n",
    "    def calc_y_pred_and_mse(self, y):\n",
    "        \"\"\"Calculates y_pred and prints the MSE.\n",
    "        \n",
    "        Parameters:\n",
    "        --------------\n",
    "        y : array    - target values for training data.\n",
    "        \"\"\"\n",
    "        assert (self.coef_ is not None), \"Model is untrained, run Model.fit(X, y) first!\"\n",
    "        y_fit = self.basis @ self.coef_\n",
    "        mse = mean_squared_error(y, y_fit)\n",
    "        print(f\"Mean squared error on data for unconstrained LS fit: {np.round(mse, 4)}\")\n",
    "        return y_fit, mse\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, lam_c=1, plot_=True, max_iter=5):\n",
    "        \"\"\"Lstsq fit using Smooths.\n",
    "        \n",
    "        Parameters:\n",
    "        -------------\n",
    "        X : pd.DataFrame or np.ndarray\n",
    "        y : pd.DataFrame or np.array\n",
    "        plot_ : boolean\n",
    "        \n",
    "        TODO:\n",
    "            [x] check constraint violation in the iterative fit\n",
    "            [x] incorporate TPS in the iterative fit\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X, self.y = X, y.ravel()\n",
    "        # create the basis for the initial fit without penalties\n",
    "        self.create_basis(X=self.X, y=self.y)    \n",
    "\n",
    "        fitting = lstsq(a=self.basis, b=y, rcond=None)\n",
    "        beta_0 = fitting[0].ravel()\n",
    "        self.coef_ = beta_0\n",
    "        self.calc_y_pred_and_mse(y=y)\n",
    "        \n",
    "        # check constraint violation\n",
    "        v_old = check_constraint_full_model(self)\n",
    "        \n",
    "        # create dataframe to save the beta values \n",
    "        colN = [ f\"b_{i}\" for i in range(len(beta_0))]        \n",
    "        df_beta = pd.DataFrame(columns=colN)\n",
    "        d = dict(zip(colN, beta_0))\n",
    "        df_beta = df_beta.append(pd.Series(d), ignore_index=True)\n",
    "        \n",
    "        beta = np.copy(beta_0)\n",
    "        \n",
    "        for i in range(max_iter):\n",
    "            print(\"Create basis with penalty and weight\")\n",
    "            self.create_penalty_block_matrix(beta_test=beta)\n",
    "            \n",
    "            print(\"Least squares fit iteration \", i+1)\n",
    "            B = self.basis\n",
    "            D_c = self.penalty_block_matrix\n",
    "            D_s = self.smoothness_penalty_matrix\n",
    "        \n",
    "            BB = B.T @ B\n",
    "            By = B.T @ y\n",
    "\n",
    "            # user defined constraint\n",
    "            DVD = D_c.T             \n",
    "            # smoothing constraint\n",
    "            DD = D_s.T @ D_s\n",
    "            \n",
    "            beta_new = (np.linalg.pinv(BB + DD + DVD) @ By).ravel()\n",
    "\n",
    "            self.calc_y_pred_and_mse(y=y)\n",
    "            \n",
    "            # create dict\n",
    "            d = dict(zip(colN, beta_new))\n",
    "            df_beta = df_beta.append(pd.Series(d), ignore_index=True)\n",
    "            \n",
    "            \n",
    "            # check constraint violation\n",
    "            v_new = check_constraint_full_model(self)\n",
    "            \n",
    "            delta_v = np.sum(v_new - v_old)\n",
    "            if delta_v == 0:\n",
    "                print(\"Iteration converged!\")\n",
    "                break\n",
    "            else:\n",
    "                v_old = v_new                \n",
    "                beta = beta_new\n",
    "                print(\"\\n Violated constraints: \", np.sum(v_new))\n",
    "            \n",
    "        self.df_beta = df_beta\n",
    "        self.coef_ = self.df_beta.iloc[-1].values\n",
    "        \n",
    "        y_fit = self.basis @ self.coef_\n",
    "    \n",
    "        self.mse = mean_squared_error(y, y_fit)\n",
    "        print(f\"Mean squared error on the data: {np.round(self.mse, 4)}\")\n",
    "        \n",
    "        if plot_:\n",
    "            dim = X.shape[1]\n",
    "            if dim == 1:\n",
    "                fig = self.plot_xy(x=X[:,0], y=y.ravel(), name=\"Data\")\n",
    "                fig.add_trace(go.Scatter(x=X[:,0], y=y_fit, name=\"Fit\", mode=\"markers\"))\n",
    "            elif dim == 2:\n",
    "                fig = go.Figure()\n",
    "                fig.add_trace(go.Scatter3d(x=X[:,0], y=X[:,1], z=y.ravel(), name=\"Data\", mode=\"markers\"))\n",
    "                fig.add_trace(go.Scatter3d(x=X[:,0], y=X[:,1], z=y_fit, name=\"Fit\", mode=\"markers\"))\n",
    "\n",
    "                \n",
    "            fig.update_traces(\n",
    "                marker=dict(\n",
    "                    size=8, \n",
    "                    line=dict(width=2, color='DarkSlateGrey')),\n",
    "                selector=dict(mode='markers'))\n",
    "\n",
    "            fig.update_layout(autosize=False, width=500, height=500)\n",
    "            fig.show()\n",
    "            \n",
    "        return y_fit\n",
    "    \n",
    "    # not trusted\n",
    "    def predict(self, X):\n",
    "        \"\"\"Prediction of the trained model on the data in X.\n",
    "        \n",
    "        Parameters:\n",
    "        ---------------\n",
    "        X : array   - Data to predict values for.\n",
    "        \n",
    "        Returns:\n",
    "        ---------------\n",
    "        pred : array  - Returns the predicted values. \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.coef_ is None:\n",
    "            print(\"Model untrained!\")\n",
    "            return\n",
    "        \n",
    "        self.X_pred = np.copy(X)\n",
    "        self.create_basis_for_prediction()\n",
    "        pred = self.basis_for_prediction @ self.coef_\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def plot_xy(self, x, y, title=\"Titel\", name=\"Data\", xlabel=\"xlabel\", ylabel=\"ylabel\"):\n",
    "        \"\"\"Basic plotting function.\"\"\"\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, name=name, mode=\"markers\"))\n",
    "        fig.update_layout(title=title)\n",
    "        fig.update_xaxes(title=xlabel)\n",
    "        fig.update_yaxes(title=ylabel)\n",
    "        return fig\n",
    "    \n",
    "    def plot_basis(self, matrix):\n",
    "        \"\"\"Plot the matrix.\"\"\"\n",
    "        fig = go.Figure(go.Image(z=matrix)).show()\n",
    "        return\n",
    "                        \n",
    "    \n",
    "def check_constraint(beta, constraint, print_idx=False, y=None, basis=None):\n",
    "    \"\"\"Checks if beta fits the constraint.\n",
    "    \n",
    "    Parameters:\n",
    "    ---------------\n",
    "    beta  : array     - Array of coefficients to be tested against the constraint.\n",
    "    constraint : str  - Name of the constraint.\n",
    "    print_idx : bool  - .\n",
    "    y  : array        - Array of data for constraint \"peak\" and \"valley\".\n",
    "    basis : ndarray   - Matrix of the basis for constraint \"peak\" and \"valley\".\n",
    "    \n",
    "    Returns:\n",
    "    ---------------\n",
    "    V : ndarray       - Matrix with 1 where the constraint is violated, 0 else.\n",
    "    \n",
    "    \"\"\"\n",
    "    V = np.zeros((len(beta), len(beta)))\n",
    "    b_diff = np.diff(beta)\n",
    "    b_diff_diff = np.diff(b_diff)\n",
    "    if constraint is \"inc\":\n",
    "        v = [0 if i > 0 else 1 for i in b_diff] #+ [0]\n",
    "    elif constraint is \"dec\":\n",
    "        v = [0 if i < 0 else 1 for i in b_diff] #+ [0]\n",
    "    elif constraint is \"conv\":\n",
    "        v = [0 if i > 0 else 1 for i in b_diff_diff] #+ [0,0]\n",
    "    elif constraint is \"conc\":\n",
    "        v = [0 if i < 0 else 1 for i in b_diff_diff] #+ [0,0]\n",
    "    elif constraint is \"no\":\n",
    "        v = list(np.zeros(len(beta), dtype=np.int))\n",
    "    elif constraint is \"smooth\":\n",
    "        v = list(np.ones(len(b_diff_diff), dtype=np.int)) #+ [0,0]\n",
    "    elif constraint is \"tps\":\n",
    "        v = list(np.ones(len(beta), dtype=np.int))\n",
    "    elif constraint is \"peak\":\n",
    "        assert (y is not None), \"Include y in check_constraints for penalty=[peak]\"\n",
    "        assert (basis is not None), \"Include basis in check_constraints for penalty=[peak]\"\n",
    "\n",
    "        peak, properties = find_peaks(x=y, distance=int(len(y)))\n",
    "        border = np.argwhere(basis[peak,:] > 0)\n",
    "        left_border_spline_idx = int(border[0][1])\n",
    "        right_border_spline_idx = int(border[-1][1])\n",
    "        v_inc = [0 if i > 0 else 1 for i in b_diff[:left_border_spline_idx]]\n",
    "        v_dec = [0 if i < 0 else 1 for i in b_diff[right_border_spline_idx:]]\n",
    "        v_plateau = np.zeros(right_border_spline_idx - left_border_spline_idx + 1)\n",
    "        v = np.concatenate([v_inc, v_plateau, v_dec]) \n",
    "        \n",
    "        # delete the last two entries\n",
    "        v = v[:-2]\n",
    "        \n",
    "    elif constraint is \"valley\":\n",
    "        assert (y is not None), \"Include y in check_constraints for penalty=[valley]\"\n",
    "        assert (basis is not None), \"Include basis in check_constraints for penalty=[peak]\"\n",
    "\n",
    "        peak, properties = find_peaks(x= -1*y, distance=int(len(y)))\n",
    "        border = np.argwhere(basis[peak,:] > 0)\n",
    "        left_border_spline_idx = int(border[0][1])\n",
    "        right_border_spline_idx = int(border[-1][1])\n",
    "        v_dec = [0 if i < 0 else 1 for i in b_diff[:left_border_spline_idx:]]\n",
    "        v_inc = [0 if i > 0 else 1 for i in b_diff[right_border_spline_idx:]]\n",
    "        v_plateau = np.zeros(right_border_spline_idx - left_border_spline_idx + 1)\n",
    "        v = np.concatenate([v_dec, v_plateau, v_inc])\n",
    "        \n",
    "        # delete the last two entries\n",
    "        v = v[:-2]\n",
    "    \n",
    "    else:\n",
    "        print(f\"Constraint [{constraint}] not implemented!\")\n",
    "        return    \n",
    "    \n",
    "    V = np.diag(v)\n",
    "    \n",
    "    if print_idx:\n",
    "        print(\"Constraint violated at the following indices: \")\n",
    "        print([idx for idx, n in enumerate(v) if n == 1])\n",
    "    return V\n",
    "\n",
    "def check_constraint_full_model(model):\n",
    "    \"\"\"Checks if the coefficients in the model violate the given constraints.\n",
    "    \n",
    "    Parameters:\n",
    "    -------------\n",
    "    model : class Model() \n",
    "    \n",
    "    Returns:\n",
    "    -------------\n",
    "    v : list   - list of boolean wheter the constraint is violated. \n",
    "    \"\"\"\n",
    "\n",
    "    assert (model.coef_ is not None), \"Please run Model.fit(X, y) first!\"\n",
    "    v = []\n",
    "\n",
    "    for i, smooth in enumerate(model.smooths):\n",
    "        beta = model.coef_[model.coef_list[i]:model.coef_list[i+1]]\n",
    "        penalty = smooth.penalty\n",
    "        V = check_constraint(beta, constraint=penalty, y=model.y, basis=model.basis)\n",
    "        v += list(np.diag(V))\n",
    "    \n",
    "    return np.array(v, dtype=np.int)    \n",
    "    \n",
    "def bar_chart_of_coefficient_difference_dataframe(df):\n",
    "    \"\"\"Takes the dataframe Model.df_beta and plots a bar chart of the rows. \"\"\"\n",
    "\n",
    "    fig = go.Figure()\n",
    "    x = np.arange(df.shape[1]-1)\n",
    "    xx = df.columns[1:]\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        fig.add_trace(go.Bar(x=xx, y=np.diff(df.iloc[i]), name=f\"Iteration {i}\"))\n",
    "        \n",
    "    fig.update_xaxes(\n",
    "        showgrid=True,\n",
    "        ticks=\"outside\",\n",
    "        tickson=\"boundaries\",\n",
    "        ticklen=20\n",
    "    )\n",
    "    fig.update_layout(title=\"Difference in coefficients\", )\n",
    "    fig.show()        \n",
    "        \n",
    "def line_chart_of_coefficient_dataframe(df):\n",
    "    \"\"\"Takes the dataframe Model.df_beta and plots a line chart of the rows. \"\"\"\n",
    "\n",
    "    fig = go.Figure()\n",
    "    x = np.arange(df.shape[1])\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df.iloc[i], name=f\"Iteration {i}\",\n",
    "                                mode=\"lines\"))\n",
    "\n",
    "    fig.update_layout(title=\"Coefficients at different iterations\",)\n",
    "    fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

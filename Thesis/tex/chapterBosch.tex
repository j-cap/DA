\chapter{Boshc Data} \label{cha:real-world-application2}

As second example, we will now investigate the behavior of a servo-compensation, see~\pref{fig:blockschaltbild}. The region of interest is marked by the red square. We try to model the differential current $i_m^d$ by two inputs. The first input is the measured position of the main valve $s_h$. The second input is the differential flow $q_p^d$. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\columnwidth]{graphics/pgfplots/chaBosch/blockschaltbild.png}
	\caption{Blockschaltbild}
	\label{fig:blockschaltbild}
\end{figure}

The data is generated by using a validated model based on first-principles and is visualized in Figure \ref{fig:bosch_data_situation}. We know beforehand that the differential current $i_m^d$ is monotonic increasing with the differential flow $q_p^d$. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\columnwidth]{graphics/pgfplots/chaBosch/data_situation.png}
	\caption{Data Situation}
	\label{fig:bosch_data_situation}
\end{figure}

We will now again use various models based on B-spline bases, tensor-product B-spline bases and their shape-constraint alternatives to recover a model for the differential current. The following list, in which $s(i)$ denotes the use of a B-spline basis for input $i$ and $t(1,2)$ denotes the use of a tensor-product B-spline basis for inputs $i$ and $j$, describes the models.

\begin{enumerate}[(i)]
	\item M1 $= s(1) + s(2)$
	\item M2 $= s(1) + s(2)$, using monotonicity for $s(2)$
	\item M3 $= t(1,2)$
	\item M4 $= t(1,2)$, using monotonicity for input $s(1)$ and $s(2)$
	\item M5 $= s(2) + t(1,2)$, as additive model 
	\item M6 $= s(2) + t(1,2)$, as additive model using the constraints in M2 and M4
\end{enumerate}
%
To fit the models listed above, we perform a randomized train-validation split on the data, i.e. we split the data into a training set $\mathcal{D}_{\text{train}}$ and a validation set $\mathcal{D}_{\text{val}}$, fit the models to the resulting training set and evaluate its performance by calculating the mean squared error on the validation set $\mathcal{D}_{\text{val}}$ as well as by visual inspection.


Note that we use a smoothness penalty optimized via generalized cross-validation for each individual basis. The unconstraint models M1, M3 and M5 are therefore P-spline models rather than B-spline models. The shape-constraint models M2, M4 and M6 are SCP-spline models. 


\begin{comment}
content...
%
The mean squared errors evaluated on the validations set $\mathcal{D}_{\text{val}}$ are given in~\pref{tab:ebner-mse-val}. According to these, the best model is M4, i.e. the shape-constraint tensor-product B-spline with a monotonicity constraint in the mass flow dimension. The models M3, i.e. the tensor-product B-spline, and M6, i.e. the additive model using shape-constraints, perform nearly as well as M4 according to the mean squared error on the validation set. 

\begin{table}[H]
	\begin{center}
		\pgfplotstabletypeset[
		col sep=comma,
		columns/Model/.style={string type},
		columns/MSE_val/.style={column name={$\text{MSE}_{\text{val}}$}},
		every head row/.style={before row=\toprule[1pt] \toprule,after row=\midrule[2pt]},
		every last row/.style={after row=\bottomrule \bottomrule},
		every nth row={1}{before row=\midrule},
		]{graphics/data/cha5/mses.csv}
	\end{center}
	\caption{Mean squared errors on the validation set $\mathcal{D}_{\text{val}}$.}
	\label{tab:ebner-mse-val}
\end{table}

The predictions for model M4 are shown in~\pref{fig:ebner-M4}. The peak behavior in the temperature dimension is clearly visible, as well as an increasing trend within the massflow dimension. Therefore, we conclude that model M4 is the superior model with regards to the domain knowledge and data fidelity. 

\begin{figure}[H]
	\centering
	\includegraphics[width=\columnwidth]{graphics/pgfplots/cha5/M4.pdf}
	\caption{Validation set $\mathcal{D}_{\text{val}}$ and predictions by model M4.}
	\label{fig:ebner-M4}
\end{figure}

The predictions for model M6 are shown in~\pref{fig:ebner-M6}. Here, the peak behavior can also be identified, but in a weaker fashion as for model M4 in~\pref{fig:ebner-M4}. We also obtain an increasing trend in the massflow dimension. 

\begin{figure}[H]
	\centering
	\includegraphics[width=\columnwidth]{graphics/pgfplots/cha5/M6.pdf}
	\caption{Validation set $\mathcal{D}_{\text{val}}$ and predictions by model M6.}
	\label{fig:ebner-M6}
\end{figure}
%
The visual inspection of the predictions of model M3 in~\pref{fig:ebner-M3} indicates that there is massive overfitting present. Neither smooth, nor the a priori known behavior (increasing in the massflow dimension and a peak behavior in the temperature dimension) is identifiable.  

\begin{figure}[H]
	\centering
	\includegraphics[width=\columnwidth]{graphics/pgfplots/cha5/M3.pdf}
	\caption{Validation set $\mathcal{D}_{\text{val}}$ and predictions by model M3.}
	\label{fig:ebner-M3}
\end{figure}

We omit the visual presentation of the predictions by the models M1, M2 and M5, since for all of these the mean squared errors on the validation set $\mathcal{D}_{\text{val}}$ is at least a magnitude higher, indicating even worse models.

To summarized, we see that the incorporation of a priori domain knowledge improves the quality of the fit in all of the above models, e.g. M2 is the better model according to the mean squared error on the validation set $\mathcal{D}_{\text{val}}$ than M1, M4 is better than M3 and M6 is better than M5. Therefore, we conclude that the use of a priori domain knowledge through shape-constraints improves the model quality for our real-world data example. 

\end{comment}
